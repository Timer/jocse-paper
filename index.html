<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="Joseph S. Haddad The University of Akron 302 E Buchtel Ave Akron, OH, 44325, United States jsh77@zips.uakron.edu" />
  <meta name="author" content="Timothy W. O’Neil The University of Akron 302 E Buchtel Ave Akron, OH, 44325, United States toneil@uakron.edu" />
  <meta name="author" content="Anthony Deeter The University of Akron 302 E Buchtel Ave Akron, OH, 44325, United States aed27@zips.uakron.edu" />
  <meta name="author" content="Zhong-Hui Duan The University of Akron 302 E Buchtel Ave Akron, OH, 44325, United States duan@uakron.edu" />
  <title>STUDENT PAPER: An Implementation of Parallel Bayesian Network Learning</title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #0000ff; } /* Keyword */
code > span.ch { color: #008080; } /* Char */
code > span.st { color: #008080; } /* String */
code > span.co { color: #008000; } /* Comment */
code > span.ot { color: #ff4000; } /* Other */
code > span.al { color: #ff0000; } /* Alert */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #008000; font-weight: bold; } /* Warning */
code > span.cn { } /* Constant */
code > span.sc { color: #008080; } /* SpecialChar */
code > span.vs { color: #008080; } /* VerbatimString */
code > span.ss { color: #008080; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { } /* Variable */
code > span.cf { color: #0000ff; } /* ControlFlow */
code > span.op { } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #ff4000; } /* Preprocessor */
code > span.do { color: #008000; } /* Documentation */
code > span.an { color: #008000; } /* Annotation */
code > span.cv { color: #008000; } /* CommentVar */
code > span.at { } /* Attribute */
code > span.in { color: #008000; } /* Information */
  </style>
  <link rel="stylesheet" href="pandoc.css" type="text/css" />
</head>
<body>
<div id="header">
<h1 class="title">STUDENT PAPER: An Implementation of Parallel Bayesian Network Learning</h1>
<h2 class="author"><p>Joseph S. Haddad<br />
The University of Akron<br />
302 E Buchtel Ave<br />
Akron, OH, 44325, United States<br />
jsh77@zips.uakron.edu</p></h2>
<h2 class="author"><p>Timothy W. O’Neil<br />
The University of Akron<br />
302 E Buchtel Ave<br />
Akron, OH, 44325, United States<br />
toneil@uakron.edu</p></h2>
<h2 class="author"><p>Anthony Deeter<br />
The University of Akron<br />
302 E Buchtel Ave<br />
Akron, OH, 44325, United States<br />
aed27@zips.uakron.edu</p></h2>
<h2 class="author"><p>Zhong-Hui Duan<br />
The University of Akron<br />
302 E Buchtel Ave<br />
Akron, OH, 44325, United States<br />
duan@uakron.edu</p></h2>
</div>
<div id="TOC">
<ul>
<li><a href="#introduction"><span class="toc-section-number">1</span> Introduction</a></li>
<li><a href="#background"><span class="toc-section-number">2</span> Background</a><ul>
<li><a href="#bayesian-networks"><span class="toc-section-number">2.1</span> Bayesian Networks</a></li>
<li><a href="#openmp"><span class="toc-section-number">2.2</span> OpenMP</a></li>
<li><a href="#mpi"><span class="toc-section-number">2.3</span> MPI</a></li>
</ul></li>
<li><a href="#methodology"><span class="toc-section-number">3</span> Methodology</a><ul>
<li><a href="#processors"><span class="toc-section-number">3.1</span> Processors</a></li>
<li><a href="#cluster-parallelism"><span class="toc-section-number">3.2</span> Cluster Parallelism</a></li>
</ul></li>
<li><a href="#results-and-discussion"><span class="toc-section-number">4</span> Results and Discussion</a><ul>
<li><a href="#processors-1"><span class="toc-section-number">4.1</span> Processors</a></li>
<li><a href="#cluster-parallelism-1"><span class="toc-section-number">4.2</span> Cluster Parallelism</a></li>
</ul></li>
<li><a href="#conclusion"><span class="toc-section-number">5</span> Conclusion</a></li>
<li><a href="#reflections"><span class="toc-section-number">6</span> Reflections</a></li>
<li><a href="#acknowledgments"><span class="toc-section-number">7</span> Acknowledgments</a></li>
</ul>
</div>
<h1 id="introduction"><span class="header-section-number">1</span> Introduction</h1>
<p>Inferring relations among genes requires a significant amount of data. Bayesian networks may be used to correlate this data and extract relationships among the genes <span class="citation">Sriram (2011)</span>. We do not know what this relationship is, but we do know it has a high likelihood of existing. These relationships can then be used to make testable hypotheses to determine how gene interactions influence life in organisms or humans. As a result, tests can be performed in the lab with more confidence and a reduced chance of wasting time and resources.</p>
<p>This concept has been applied to smaller data sets and shows promising results <span class="citation">Sriram (2011)</span>, however remains too slow to be applied to a larger problem. It is our objective to decrease the runtime required to form a network which may reveal genetic interactions. Bayesian network learning, however, is inherently slow because it is an NP-hard algorithm <span class="citation">Cooper and Herskovits (1992)</span>. Search space reduction algorithms may be utilized to reduce the computational complexity. K2 is a great example of a search space reduction algorithm, and is our algorithm of choice. However, it introduces a new problem. K2 restricts the parent hierarchy of genes within the network <span class="citation">Cooper and Herskovits (1992)</span>, and thus introduces bias in the computed relations. To achieve high confidence in the generated networks, an abundance of Bayesian networks need to be computed using random search space restrictions. These random search space restrictions (or topologies) remove the bias and provide results which can be interpreted at various levels of confidence.</p>
<p>By eliminating one problem and introducing another, consensus networks enable the ability of parallelization by requiring multiple units of work rather than just one faster unit of work. Other authors describe parallel implementations that can increase the speed of Bayesian network learning <span class="citation">Altekar et al. (2004)</span> <span class="citation">Misra et al. (2014)</span>. However, no libraries exist which compute multiple Bayesian networks concurrently. This project examines the value of Bayesian network learning within a parallel environment in order to reduce the time needed to generate consensus networks using many topological inputs. This examination is performed through implementation of the said algorithm, exploring methods available such as OpenMP and MPI.</p>
<p>Results from running experiments with varying number of cores and machines are examined and it is found our parallelization has a positive impact. There are a couple caveats, however, such as the over provisioning of resources which leads to waste and potential introduction of latency from cluster parallelism. When the resources are appropriate for the problem size, OpenMP and MPI substantially reduce the time to generate a consensus network. The reduction in runtime appears to be linear, more so after accounting for introduced latency and overhead.</p>
<p>This paper is an extension to the initial analysis performed on the algorithm and explains the thought processes behind the implementation. The preceding publication shows why the algorithm needs to be sped up, as an increase in samples causes linear growth of the problem and introduction of additional genes causes exponential growth of the problem <span class="citation">Haddad et al. (2016)</span>. After reading this paper, the reader should have a sense of why and how the parallelization was reasoned about and implemented to achieve optimal efficiency.</p>
<h1 id="background"><span class="header-section-number">2</span> Background</h1>
<h2 id="bayesian-networks"><span class="header-section-number">2.1</span> Bayesian Networks</h2>
<p>Bayesian networks capture qualitative relationships among variables within a directed acyclic graph (or DAG). Nodes within the DAG represent variables, and edges represent dependencies between the variables <span class="citation">Korb and Nicholson (2003)</span> <span class="citation">Pearl (1998)</span>. Bayesian networks have a search space which grows exponentially when introducing new nodes and not placing restrictions on the structure of the network. This complication can be overcome by using the K2 algorithm. The K2 algorithm reduces the computational cost of learning by imposing restraints on parent node connections via topological ordering <span class="citation">Cooper and Herskovits (1992)</span>. Here, a topology refers to a hierarchical structure of parenthood that the K2 algorithm will utilize to reduce overall computational complexity while scoring data relationships. Restricting the parent ordering, however, creates an issue of bias, which is inherent within a constraint-based search space reduction <span class="citation">Sriram (2011)</span>. Sriram <span class="citation">Sriram (2011)</span> proposed a solution to this issue by creating a consensus network, or the combination of multiple Bayesian networks derived from several topological inputs. To eliminate the bias created by these restraints, many randomly generated topologies are used. By increasing the number of topological inputs, the consensus network has a greater chance of reflecting the true nature of the gene interactions with higher levels of confidence.</p>
<h2 id="openmp"><span class="header-section-number">2.2</span> OpenMP</h2>
<p>OpenMP or (Open Multi-Processing) is a cross-platform, multilingual application programming interface (API) which enables shared-memory parallel programming on a single machine. The OpenMP specification consists of compiler directives and library functions used to parallelize portions of a program’s control flow <span class="citation">(“OpenMP Application Program Interface,” n.d.)</span>. The most rudimentary example of OpenMP would be to distribute a for-loop across multiple threads.</p>
<p>An advisory board of top entities in computation controls its specification <span class="citation">(“About the OpenMP ARB and OpenMP.org,” n.d.)</span> which can be implemented by various compilers to target specific system capabilities and architectures. The specification includes language-specific APIs, compiler directives, and standardized environment variables <span class="citation">(“OpenMP Application Program Interface,” n.d.)</span>. The model of OpenMP is comparable to the fork-join model, but provides additional convenience (cross-platform) features through compiler directives. These directives consist of, but are not limited to, barriers, critical regions, variable atomicity, shared memory, and reductions <span class="citation">(“OpenMP Application Program Interface,” n.d.)</span>.</p>
<p>OpenMP enables parallel code portability at a level which would not be achievable while retaining an ideal code climate. OpenMP, by nature allows simple and straight-forward parallelization of loops with a compiler directive that targets the system for which the program is compiled on. Without OpenMP, the program would have to include many different libraries and routines to achieve parallel code across different systems. The result of this would be a program which only works on a specific set of machines, or a code base which is hard to maintain and debug when changes are made to the underlying algorithm.</p>
<h2 id="mpi"><span class="header-section-number">2.3</span> MPI</h2>
<p>MPI (or Message Passing Interface) is a standard which outlines network-routed (a)synchronous communication between machines <span class="citation">(“MPI: A Message-Passing Interface Standard,” n.d.)</span>. MPI enables executing programs across multiple machines in a cluster and passing messages between them to schedule work or share information.</p>
<p>Execution of a program which utilizes MPI is most often performed with a tool. This tool is responsible for forwarding appropriate parameters to each program in order to specify the information required for the processes to communicate. Upon program start, the MPI execution environment must be initialized using the MPI library methods <span class="citation">(“MPI: A Message-Passing Interface Standard,” n.d.)</span>. The initialization sequence results in augmented program arguments (to remove arguments passed by the execution tool) and the rank of the program in the MPI environment <span class="citation">(“MPI: A Message-Passing Interface Standard,” n.d.)</span>. This information allows the program to proceed as normal while being a small part in a larger sum.</p>
<h1 id="methodology"><span class="header-section-number">3</span> Methodology</h1>
<p>Testing was performed on the Blue Waters petascale machine at the University of Illinois at Urbana-Champaign. The facility is maintained by Cray and consists of 22,640 Cray XE6 machines and 3,072 XK7 machines, which are CPU-only and GPU-accelerated machines respectively. The XE6 machines consist of two 16 core AMD processors with 64 GBs of RAM. The XK7 machines consist of a single 16 core AMD processor with 32 GBs of RAM and a NVIDIA K20X GPU <span class="citation">(“Lessons Learned From the Analysis of System Failures at Petascale: The Case of Blue Waters,” n.d.)</span>.</p>
<p>Cray XE6 machines were used to perform all tests utilizing purely synthetic data. OpenMP and MPI were implemented by the Cray Compiler, Cray C version 8.3.10. The synthetic data is in the form of a gene-by-sample matrix consisting of the presence or absence of each gene within the sample. This data was generated according to a model we defined. We then ensured the result of the consensus network(s) matched our model to validate functionality and evaluate a degree of correctness for our algorithm. Each test was run five times with the mean, standard deviation, and standard error calculated to measure runtime consistency.</p>
<p>The library being used to run the tests is available online <span class="citation">(“Bayesian Learning Source Code,” n.d.)</span>. This library was implemented as described in this paper.</p>
<h2 id="processors"><span class="header-section-number">3.1</span> Processors</h2>
<p>The first natural step in parallelizing computation is to attempt to use multiple cores (or threads) simultaneously on the machine. This can be done by running multiple instances of the program, or by implementing code which takes advantage of multiple threads. Analyzing the program reveals a couple potential places for parallelization. There are many for-loops which perform actions which are independent from one another. The for-loops identified for inspection are the generation of topologies and the iteration over the topologies to generate networks.</p>
<p>The generation of topologies results in a a predetermined number of topologies filled into an array. This operation can be easily parallelized across multiple cores as they are independent. The appropriate tool to perform this parallelization is OpenMP. OpenMP was implemented with a simple compiler directive which sped up computation.</p>
<div class="sourceCode"><pre class="sourceCode cpp"><code class="sourceCode cpp"><span class="ot">#pragma omp parallel for</span>
<span class="kw">for</span> (...) { }</code></pre></div>
<p>Iterating over the topologies to generate networks can also be parallelized. The creation of Bayesian networks are independent from one another, and thus, networks can be asynchronously generated. Implementation of this parallelization is straight-forward as Bayesian network computation does not mutate its data set. This prevents us from having to replicate the memory and increase the space complexity of the algorithm. OpenMP was implemented again as shown above. Additionally, within the parallel for, the resulting network must be appended to the consensus network. The consensus network, however, is not thread-safe and must be operated on within a critical section. A critical section specifies that the code can only be executed on one thread at a time.</p>
<div class="sourceCode"><pre class="sourceCode cpp"><code class="sourceCode cpp"><span class="ot">#pragma omp critical</span>
<span class="kw">for</span> (...) { }</code></pre></div>
<p>This ensures the networks are properly summed together, otherwise, an addition may be lost. For example, if <code>Thread A</code> and <code>Thread B</code> attempt to increment a variable at the same time, they may both access the value before the other commits the new value. This will result in a lost operation, as the threads are not aware of one another.</p>
<p>To measure the resulting computational runtime decrease, multiple tests were performed with varying number of processors. A single set of synthetic data was used which consisted of 10 genes and 10,000 samples. Using an exclusively reserved machine, tests were run by varying the number of processors (up to 32) and measuring the algorithm performance for the creation of 160 Bayesian networks per gene 1600 total). We have reached the resource limits on the systems which we have access to, and cannot test beyond 32 cores. The selection of 10 genes and 160 Bayesian networks was arbitrarily chosen as sufficient means to measure computation time.</p>
<h2 id="cluster-parallelism"><span class="header-section-number">3.2</span> Cluster Parallelism</h2>
<p>Distributing work across multiple machines requires a different approach than that of OpenMP. OpenMP cannot share memory across machines so it cannot be applied to this situation. MPI is optimal for this situation as it allows machines to send messages back and forth to share memory and communicate their responsibilities and results. Distributing the Bayesian network learning process across multiple machines doesn’t make much sense because each step is dependent on the previous, so the result would be a slower computation since calculations couldn’t happen in parallel and there would be added network latency. The main candidate for distribution would be the computation of a Bayesian network (or the iteration over the topologies), because networks are computed independent of one another and there is a large backlog of networks which need to be computed. Distributing the work with MPI is surprisingly simple, as the topologies are randomly generated. This means there is no communication required prior to beginning computation. Upon initialization, each machine must determine its rank and role by augmenting the arguments, this may be done like so.</p>
<div class="sourceCode"><pre class="sourceCode c"><code class="sourceCode c"><span class="dt">int</span> main(<span class="dt">int</span> argc, <span class="dt">char</span> **argv) {
  <span class="dt">int</span> forkIndex = <span class="dv">0</span>, forkSize = <span class="dv">1</span>;
  MPI_Init(&amp;argc, &amp;argv);
  MPI_Comm_rank(MPI_COMM_WORLD, &amp;forkIndex);
  MPI_Comm_size(MPI_COMM_WORLD, &amp;forkSize);

  ...
}</code></pre></div>
<p>Each machine can then determine how much work it needs to do by dividing the number of requested topologies per gene by the number of machines in the swarm.</p>
<div class="sourceCode"><pre class="sourceCode c"><code class="sourceCode c"><span class="dt">int</span> top_d = topologies / forkSize;
<span class="dt">int</span> top_r = topologies % forkSize;
<span class="kw">if</span> (forkIndex &lt; top_r) ++top_d;
topologies = top_d;</code></pre></div>
<p>When the machines complete their share of the computation they communicate to coalesce the computed networks into a consensus network. The master machine then saves the consensus network to the disk and completes any other required computations which are simple enough not to require being distributed across machines.</p>
<p>Tests are conducted to measure the impact on runtime when multiple machines are used. The same data is used from the above (processors) test. Tests were run on dedicated machines utilizing 16 processors and computing 60 Bayesian networks per gene (600 total). The selection of 10 genes and 60 Bayesian networks was arbitrarily chosen as sufficient means to measure computation time.</p>
<h1 id="results-and-discussion"><span class="header-section-number">4</span> Results and Discussion</h1>
<p>In the following tables, the standard deviation is represented by the letter <code>s</code> and the standard error is denoted by <code>se</code>. This standard deviation and error is in regards to the algorithm runtime, not the accuracy of the algorithm.</p>
<h2 id="processors-1"><span class="header-section-number">4.1</span> Processors</h2>
<p>When increasing the number of processors, the resulting runtime decrease appears to be linear. The linear nature of the results removes the necessity for further testing between the number of cores tested. Figure 1 illustrates that as the number of processors increase, the runtime decreases at approximately the same rate. Exact results may be seen in Table 1.</p>
<div class="figure">
<img src="https://puu.sh/qH05S/2838bb28d0.png" alt="Illustrates runtime decrease as the number of processors increase. The decline is nearly linear." />
<p class="caption">Illustrates runtime decrease as the number of processors increase. The decline is nearly linear.</p>
</div>

<p>This linear decrease is consistent with how OpenMP distributes its work. OpenMP distributes the task of an independent Bayesian network computation across multiple threads simultaneously. These independent tasks are non-blocking and do not lock one another, and thus have very little contention. There is one lock after each computation which appends the network to the consensus network, but is negligible to the total time taken to compute the Bayesian networks. OpenMP results in such low runtime standard error because it works with memory within the program and requires no network communication like MPI. The reduction of standard error as the number of threads increase may be due to the kernel. The kernel is responsible for scheduling threads and ensuring other work on the system gets done. The increase in threads means there are more threads which may go uninterrupted by the kernel scheduling something else from the operating system.</p>
<h2 id="cluster-parallelism-1"><span class="header-section-number">4.2</span> Cluster Parallelism</h2>
<p>The resulting runtime decrease also appears to be linear while increasing the number of machines. However, as the number of machines increase, overhead also increases. Figure 2 demonstrates that as the number of machines increase, there is much more variation introduced and overhead in the runtime.</p>
<p>Observing 64 machines and leading up to 64 machines, it can be noted that the reduction in runtime becomes less and less and then starts increasing. This increase in runtime happens when the inflection point has been reached for the given set of data. At some point, it takes longer to send the data over the network than it would be to simply compute more data on fewer machines. There are some potential modifications which can be made to mitigate this overhead (such as asynchronous coalescing), but it cannot be eliminated completely. It is important to note that an increase in resources does not necessarily mean an increase in performance, nor always one for one; see Table 2 for test results.</p>
<div class="figure">
<img src="https://puu.sh/qH0MG/5a05712a80.png" alt="Illustrates runtime decrease as the number of machines increase. The decline is nearly linear." />
<p class="caption">Illustrates runtime decrease as the number of machines increase. The decline is nearly linear.</p>
</div>

<p>The standard error generally increases with the increase in machines, but this is not always true. There does not seem to be a correlation between an increase or decrease in machines with an increase or decrease in standard error, except for the general rule stated above. This is consistent with the fact that networks are very unpredictable. Pings may vary wildly depending on other network traffic and the route which packets decide to take. Additionally, there may be other noisy peers on the network hogging bandwidth and causing slower transmissions. On clusters across the world wide web, traffic may have to travel through geographical displacement and suffer packet loss or increases in latency. The only thing consistent with the standard error is that it is not consistent.</p>
<h1 id="conclusion"><span class="header-section-number">5</span> Conclusion</h1>
<p>By generating a consensus network out of many Bayesian networks, researchers may screen and infer new gene interactions. This allows researchers to feel more confident about testing hypotheses in the lab, such that their resources and time will not be wasted.</p>
<p>We have concluded that utilizing parallelization through means of OpenMP and MPI substantially reduces the time to generate a consensus network. However, as demonstrated in the graphs above, an increase in resources must be tailored to the problem at hand. Increasing the resources too significantly becomes detrimental, resulting in costly waste; see Table 2.</p>
<p>Future work may involve parallelizing the coalescing of consensus networks in effort to reduce the overhead introduced when increasing cluster parallelism. Additionally, all matrix operations are currently done on a single-thread. These operations (in some cases) contain thousands of rows and columns being applied to an expensive mathematical function. These operations are ideal for the GPU as it can perform the arithmetic across several thousand of threads simultaneously. As such, the motivation for this is that CUDA (or other means of GPGPU acceleration) has the potential to speed the algorithm up by several orders of magnitude.</p>
<h1 id="reflections"><span class="header-section-number">6</span> Reflections</h1>
<p>Working on this project gave me a massive amount of experience, which far surpassed what I thought it would. I gained experience in professional writing for journal publications and renewed my skills in proofreading. I also gained exposure to a whole new aspect of project organization which I was not used to: meetings with advisors, progress reports, and demos. I feel like this has really helped foster my professional identity and prepared me more for higher education and the workforce. Additionally, I flexed my problem solving skills while implementing the algorithm and begun refactoring. The refactoring had to be done in such a fashion to allow for parallelization. This presented some challenges because there were also memory considerations to make things sharable over the network (MPI). Overall, I learned many invaluable skills which will be applied to my future education and work. Notably, I performed my first publication <span class="citation">Haddad et al. (2016)</span> and gave a presentation at the associated conference, then proceeded to present a poster version of the paper at GLBIO 2016 to draw attention to the work.</p>
<h1 id="acknowledgments"><span class="header-section-number">7</span> Acknowledgments</h1>
<p>This research is part of the Blue Waters sustained-petascale computing project, which is supported by the National Science Foundation (awards OCI-0725070 and ACI-1238993) and the state of Illinois. Blue Waters is a joint effort of the University of Illinois at Urbana-Champaign and its National Center for Supercomputing Applications.</p>
<p>Additional financial support was provided by the Buchtel College of Arts and Sciences at The University of Akron. Further support was provided by a grant from the Choose Ohio First Bioinformatics scholarship.</p>
<p>The data, statements, and views within this paper are solely the responsibility of the authors.</p>

<div id="refs" class="references">
<div id="ref-openmpboard">
<p>“About the OpenMP ARB and OpenMP.org.” n.d. <a href="http://openmp.org/wp/about-openmp/" class="uri">http://openmp.org/wp/about-openmp/</a>.</p>
</div>
<div id="ref-altekar">
<p>Altekar, Gautam, Sandhya Dwarkadas, John P. Huelsenbeck, and Fredrik Ronquist. 2004. “Parallel Metropolis Coupled Markov Chain Monte Carlo for Bayesian Phylogenetic Inference.” Bioinformatics.</p>
</div>
<div id="ref-sourcecode">
<p>“Bayesian Learning Source Code.” n.d. <a href="https://github.com/Timer/bayesian-learning" class="uri">https://github.com/Timer/bayesian-learning</a>.</p>
</div>
<div id="ref-cooper">
<p>Cooper, Gregory F., and Edward Herskovits. 1992. “A Bayesian Method for the Induction of Probabilistic Networks from Data.” Machine Learning.</p>
</div>
<div id="ref-firstpaper">
<p>Haddad, Joseph S., Anthony Deeter, Zhong-Hui Duan, and Timothy W. O’Neil. 2016. “Analysis of Parallel Bayesian Network Learning.” Proceedings of the 31st International Conference on Computers and Their Applications.</p>
</div>
<div id="ref-korb">
<p>Korb, Kevin, and Ann Nicholson. 2003. <em>Bayesian Artificial Intelligence</em>. Chapman and Hall/CRC.</p>
</div>
<div id="ref-bwinfo">
<p>“Lessons Learned From the Analysis of System Failures at Petascale: The Case of Blue Waters.” n.d. <a href="https://courses.engr.illinois.edu/ece542/sp2014/finalexam/papers/bluewaters.pdf" class="uri">https://courses.engr.illinois.edu/ece542/sp2014/finalexam/papers/bluewaters.pdf</a>.</p>
</div>
<div id="ref-misra">
<p>Misra, Sanchit, Vasimuddin Md, Kiran Pamnany, Sriram P. Chockalingam, Yong Dong, Min Xie, Maneesha R. Aluru, and Srinivas Aluru. 2014. “Parallel Bayesian Network Structure Learning for Genome-Scale Gene Networks.” International Conference for High Performance Computing, Networking, Storage and Analysis.</p>
</div>
<div id="ref-mpispec">
<p>“MPI: A Message-Passing Interface Standard.” n.d. <a href="http://www.mpi-forum.org/docs/mpi-3.0/mpi30-report.pdf" class="uri">http://www.mpi-forum.org/docs/mpi-3.0/mpi30-report.pdf</a>.</p>
</div>
<div id="ref-openmpapi">
<p>“OpenMP Application Program Interface.” n.d. <a href="http://www.openmp.org/mp-documents/OpenMP4.0.0.pdf" class="uri">http://www.openmp.org/mp-documents/OpenMP4.0.0.pdf</a>.</p>
</div>
<div id="ref-pearl">
<p>Pearl, Judea. 1998. <em>Probabilistic Inference in Intelligent Systems</em>. Morgan Kaufmann Publishers.</p>
</div>
<div id="ref-sriram">
<p>Sriram, Aparna. 2011. “Predicting Gene Relations Using Bayesian Networks.” MS thesis, University of Akron. <a href="https://etd.ohiolink.edu/pg_10?0::NO:10:P10_ETD_SUBID:47568" class="uri">https://etd.ohiolink.edu/pg_10?0::NO:10:P10_ETD_SUBID:47568</a>.</p>
</div>
</div>
</body>
</html>
